{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----import libraries----------------------------------------#\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import wrappers\n",
    "import random as rand\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#-----set up environment------------------------------------#\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random weight generation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_moves = 0\n",
    "episode_length = []\n",
    "best_weights = np.zeros(4) #emmpty 4 digit array\n",
    "\n",
    "for i in range (100):\n",
    "    new_weights = [rand.uniform(0,1),rand.uniform(0,1),rand.uniform(0,1),rand.uniform(0,1)]\n",
    "    moves_length = []\n",
    "    for j in range(100):\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        while not done:\n",
    "            count+=1\n",
    "            action = 1 if np.dot(observation,new_weights)>0 else  0\n",
    "            observation,reward,done,_ = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "        moves_length.append(count)\n",
    "    avg_moves = float(sum(moves_length)/len(moves_length))\n",
    "    if avg_moves > best_moves:\n",
    "        best_moves = avg_moves\n",
    "        best_weights = new_weights\n",
    "    episode_length.append(avg_moves)\n",
    "    if i % 20 == 0:\n",
    "        print(\"best moves is \", best_moves)\n",
    "done = False\n",
    "counr = 0\n",
    "env = wrappers.Monitor(env, 'movefiles',force=True) #save files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting a continuouss state into a discrete state\n",
    "MAX_STATES = 10**2\n",
    "GAMMA = 0.7   #discount factor\n",
    "ALPHA = 0.001 #Learning rate\n",
    "\n",
    "#q table disctionary lookup(like weights) gets state with highest reward?\n",
    "#q table disctionary lookup(like weights) gets state with highest reward?\n",
    "def q_states_dict(q):\n",
    "    a,b = max(q.items(), key=lambda k: k[1])\n",
    "    #print(\"z\",a,b)\n",
    "    return a,b\n",
    "# our inputs\n",
    "def create_bins():\n",
    "    bins = np.zeros((4,15))\n",
    "    bins[0] = np.linspace(-2.4,2.4,15)\n",
    "    bins[1] = np.linspace(-10,10,15)\n",
    "    bins[2] = np.linspace(-41.8,41.8,15)\n",
    "    bins[3] = np.linspace(-10,10,15)\n",
    "    return bins\n",
    "#digitize bins since we are converting a continuous state to a discrete state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_bins(observation,bins):\n",
    "    env_state = np.zeros(4) #creates a single array to store the 4 states\n",
    "    for i in range(4):\n",
    "        env_state[i] = np.digitize(observation[i],bins[i])\n",
    "    return env_state\n",
    "\n",
    "def get_state_as_string(env_state):\n",
    "    env_string = ''.join(str(int(e)) for e in env_state)\n",
    "    return env_string\n",
    "\n",
    "def get_all_states_string():\n",
    "    env_states = []\n",
    "    for i in range(MAX_STATES):\n",
    "        env_states.append(str(i).zfill(8))\n",
    "    return env_states\n",
    "\n",
    "def initialise_q():\n",
    "    Q = {}\n",
    "    all_states = get_all_states_string()\n",
    "    for state in all_states:\n",
    "        Q[state] = {}\n",
    "        for action in range(env.action_space.n):\n",
    "            Q[state][action] = 0 #set rewards\n",
    "    return Q\n",
    "\n",
    "def add_state_to_table(new_state,table):\n",
    "    n_value = {}\n",
    "    n_value[new_state] = {}\n",
    "    for action in range(env.action_space.n):\n",
    "        n_value[new_state][action] = 0\n",
    "    table.update(n_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_a_game(bins,Q,eps):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    count = 0\n",
    "    new_states_created = 0\n",
    "    total_reward = 0\n",
    "    state = get_state_as_string(assign_bins(observation,bins))\n",
    "    y = Q.get(state)\n",
    "    if y == None:\n",
    "        add_state_to_table(state,Q)\n",
    "        new_states_created+=1\n",
    "    while not done:\n",
    "        #print(\"state\",state)\n",
    "        count+=1\n",
    "        init_random = np.random.uniform(0,1)\n",
    "        if init_random < eps:\n",
    "            act = env.action_space.sample() #pick a random action\n",
    "        else:\n",
    "            act,_ = q_states_dict(Q[state])\n",
    "        \n",
    "        observation,reward,done,_ = env.step(act)\n",
    "        print(\"obs1\",observation[0])\n",
    "        print(\"obs2\",env.state)\n",
    "        total_reward+=reward\n",
    "        if done and count < 200:\n",
    "            reward = -1000\n",
    "        new_state = get_state_as_string(assign_bins(observation,bins))\n",
    "        y = Q.get(new_state)\n",
    "        if y == None:\n",
    "            new_states_created+=1\n",
    "            add_state_to_table(new_state,Q)\n",
    "        a1,max_q_s1a1 = q_states_dict(Q[new_state])\n",
    "        Q[state][act]= ((1 - ALPHA)*(Q[state][act])) + ALPHA*(reward + GAMMA * max_q_s1a1)\n",
    "        state,act = new_state, a1\n",
    "        if done:\n",
    "            q_t = Q\n",
    "    return total_reward, count,new_states_created,q_t\n",
    "\n",
    "def play_multiple(bins, N):\n",
    "    Q = initialise_q()\n",
    "    count=[]\n",
    "    new_state_array = 0\n",
    "    reward = []\n",
    "    for n in range(N):\n",
    "        if n > 1:\n",
    "            epsilon = 1/np.sqrt(n+1)\n",
    "        else:\n",
    "            epsilon = 0\n",
    "        epsilon = 1/np.sqrt(n+1)\n",
    "        ep_reward,ep_length, states_created,table = play_a_game(bins,Q,epsilon)\n",
    "        new_state_array+=states_created\n",
    "        if n %10000 == 0:\n",
    "            print(n,epsilon,ep_reward,new_state_array)\n",
    "        count.append(ep_length)\n",
    "        reward.append(ep_reward)\n",
    "    return count,reward,table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs1 0.04052323389284246\n",
      "obs2 (0.04052323389284246, -0.15231754197870268, -0.02786120779074268, 0.28862340182649626)\n",
      "obs1 0.037476883053268406\n",
      "obs2 (0.037476883053268406, -0.3470313368843298, -0.022088739754212754, 0.5723906066329858)\n",
      "obs1 0.03053625631558181\n",
      "obs2 (0.03053625631558181, -0.15160673941582628, -0.010640927621553038, 0.27283165867994236)\n",
      "obs1 0.027504121527265283\n",
      "obs2 (0.027504121527265283, -0.3465752531593783, -0.005184294447954191, 0.5621394986516304)\n",
      "obs1 0.020572616464077716\n",
      "obs2 (0.020572616464077716, -0.5416240700387747, 0.006058495525078416, 0.853184616507411)\n",
      "obs1 0.009740135063302222\n",
      "obs2 (0.009740135063302222, -0.34658522567197897, 0.023122187855226635, 0.5624129059580226)\n",
      "obs1 0.002808430549862642\n",
      "obs2 (0.002808430549862642, -0.5420238858687191, 0.034370445974387084, 0.8622898509100925)\n",
      "obs1 -0.00803204716751174\n",
      "obs2 (-0.00803204716751174, -0.34738635889668673, 0.051616242992588934, 0.5806089131808381)\n",
      "obs1 -0.014979774345445474\n",
      "obs2 (-0.014979774345445474, -0.15302423390230205, 0.0632284212562057, 0.30462244743901307)\n",
      "obs1 -0.018040259023491514\n",
      "obs2 (-0.018040259023491514, 0.041142341632492335, 0.06932087020498597, 0.03253134666822238)\n",
      "obs1 -0.017217412190841667\n",
      "obs2 (-0.017217412190841667, 0.23520525758007665, 0.06997149713835041, -0.23749988009318812)\n",
      "obs1 -0.012513307039240133\n",
      "obs2 (-0.012513307039240133, 0.0391570509971049, 0.06522149953648665, 0.07640767069361243)\n",
      "obs1 -0.011730166019298036\n",
      "obs2 (-0.011730166019298036, -0.15683633255255788, 0.0667496529503589, 0.3889342027787745)\n",
      "obs1 -0.014866892670349192\n",
      "obs2 (-0.014866892670349192, 0.03727782564213358, 0.07452833700593439, 0.11802121216755734)\n",
      "obs1 -0.01412133615750652\n",
      "obs2 (-0.01412133615750652, -0.15882845062060524, 0.07688876124928554, 0.4332551067669477)\n",
      "obs1 -0.017297905169918623\n",
      "obs2 (-0.017297905169918623, -0.3549500208515515, 0.08555386338462449, 0.749151333893274)\n",
      "obs1 -0.024396905586949652\n",
      "obs2 (-0.024396905586949652, -0.16110583603563164, 0.10053689006248998, 0.4845706971924144)\n",
      "obs1 -0.027619022307662285\n",
      "obs2 (-0.027619022307662285, -0.3574921890584194, 0.11022830400633826, 0.8071708018689534)\n",
      "obs1 -0.034768866088830674\n",
      "obs2 (-0.034768866088830674, -0.16403966852508117, 0.12637172004371733, 0.5510946487193451)\n",
      "obs1 -0.0380496594593323\n",
      "obs2 (-0.0380496594593323, 0.029102013561752765, 0.13739361301810424, 0.3007468519496978)\n",
      "obs1 -0.03746761918809725\n",
      "obs2 (-0.03746761918809725, 0.22202552690864769, 0.14340855005709818, 0.05435540825586074)\n",
      "obs1 -0.033027108649924294\n",
      "obs2 (-0.033027108649924294, 0.4148311283086008, 0.14449565822221538, -0.18986641091648426)\n",
      "obs1 -0.02473048608375228\n",
      "obs2 (-0.02473048608375228, 0.6076221004447726, 0.1406983300038857, -0.43370510838034715)\n",
      "obs1 -0.012578044074856826\n",
      "obs2 (-0.012578044074856826, 0.8005009468763933, 0.13202422783627876, -0.6789354579277165)\n",
      "obs1 0.0034319748626710396\n",
      "obs2 (0.0034319748626710396, 0.6038160976173608, 0.11844551867772443, -0.34777321192322447)\n",
      "obs1 0.015508296815018256\n",
      "obs2 (0.015508296815018256, 0.4072261158174868, 0.11149005443925994, -0.0202127272523816)\n",
      "obs1 0.02365281913136799\n",
      "obs2 (0.02365281913136799, 0.2106965025079643, 0.1110857998942123, 0.3054616504352678)\n",
      "obs1 0.027866749181527276\n",
      "obs2 (0.027866749181527276, 0.014181294720135407, 0.11719503290291766, 0.6310096724604015)\n",
      "obs1 0.028150375075929983\n",
      "obs2 (0.028150375075929983, 0.20748988400904247, 0.1298152263521257, 0.37741230520629426)\n",
      "obs1 0.03230017275611083\n",
      "obs2 (0.03230017275611083, 0.010786217862592179, 0.13736347245625158, 0.7080437294402032)\n",
      "obs1 0.032515897113362675\n",
      "obs2 (0.032515897113362675, -0.18594415644979917, 0.15152434704505563, 1.0406176063434363)\n",
      "obs1 0.028797013984366692\n",
      "obs2 (0.028797013984366692, 0.006875832330294235, 0.17233669917192435, 0.7990794670878953)\n",
      "obs1 0.028934530630972576\n",
      "obs2 (0.028934530630972576, -0.1901382826534181, 0.18831828851368226, 1.1406395707079602)\n",
      "obs1 0.025131764977904213\n",
      "obs2 (0.025131764977904213, -0.38715474038012204, 0.21113107992784147, 1.4859784257497304)\n",
      "0 1.0 34.0 9\n",
      "obs1 -0.03353262358976142\n",
      "obs2 (-0.03353262358976142, 0.15782755868463225, 0.003318281345624641, -0.2766755231838596)\n",
      "obs1 -0.030376072416068774\n",
      "obs2 (-0.030376072416068774, 0.3529020118918964, -0.0022152291180525504, -0.5683100190986607)\n",
      "obs1 -0.023318032178230846\n",
      "obs2 (-0.023318032178230846, 0.15781120223074832, -0.013581429500025766, -0.2763257994527655)\n",
      "obs1 -0.02016180813361588\n",
      "obs2 (-0.02016180813361588, 0.3531242594506966, -0.019107945489081075, -0.5732611833332695)\n",
      "obs1 -0.013099322944601947\n",
      "obs2 (-0.013099322944601947, 0.15827535642763257, -0.030573169155746465, -0.286658577788868)\n",
      "obs1 -0.009933815816049296\n",
      "obs2 (-0.009933815816049296, -0.03639754429688774, -0.036306340711523825, -0.0037728008774764454)\n",
      "obs1 -0.010661766701987051\n",
      "obs2 (-0.010661766701987051, 0.15922577544872413, -0.03638179672907335, -0.3076861253444634)\n",
      "obs1 -0.0074772511930125685\n",
      "obs2 (-0.0074772511930125685, -0.03535938988367668, -0.04253551923596262, -0.02669541460005087)\n",
      "obs1 -0.008184438990686101\n",
      "obs2 (-0.008184438990686101, -0.22984635284788432, -0.04306942752796364, 0.25226948796375187)\n",
      "obs1 -0.012781366047643787\n",
      "obs2 (-0.012781366047643787, -0.42432768165496904, -0.0380240377686886, 0.531062457096555)\n",
      "obs1 -0.021267919680743166\n",
      "obs2 (-0.021267919680743166, -0.6188947239751812, -0.027402788626757504, 0.8115256897532563)\n",
      "obs1 -0.03364581416024679\n",
      "obs2 (-0.03364581416024679, -0.8136307831422037, -0.011172274831692378, 1.0954647013973564)\n",
      "obs1 -0.04991842982309087\n",
      "obs2 (-0.04991842982309087, -1.008603820211588, 0.010737019196254752, 1.384621424361196)\n",
      "obs1 -0.07009050622732263\n",
      "obs2 (-0.07009050622732263, -0.8136174041402651, 0.038429447683478675, 1.0953152821332481)\n",
      "obs1 -0.08636285431012794\n",
      "obs2 (-0.08636285431012794, -1.0092238517164718, 0.06033575332614364, 1.3998038000693553)\n",
      "obs1 -0.10654733134445737\n",
      "obs2 (-0.10654733134445737, -0.81490153260279, 0.08833182932753075, 1.1265786699083145)\n",
      "obs1 -0.12284536199651318\n",
      "obs2 (-0.12284536199651318, -0.621040967879014, 0.11086340272569704, 0.86285733462906)\n",
      "obs1 -0.13526618135409346\n",
      "obs2 (-0.13526618135409346, -0.8174835625698452, 0.12812054941827825, 1.188239383308931)\n",
      "obs1 -0.15161585260549038\n",
      "obs2 (-0.15161585260549038, -1.0140121483357365, 0.15188533708445687, 1.5181805506505448)\n",
      "obs1 -0.17189609557220512\n",
      "obs2 (-0.17189609557220512, -1.2106094755064076, 0.18224894809746778, 1.8541643723478531)\n",
      "obs1 -0.19610828508233327\n",
      "obs2 (-0.19610828508233327, -1.407207219426593, 0.21933223554442483, 2.1974621498687594)\n"
     ]
    }
   ],
   "source": [
    "bins = create_bins()\n",
    "x,y,table = play_multiple(bins,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table\n",
    "import pandas as pd\n",
    "q_tdf =  pd.DataFrame(table)\n",
    "q_tdf.to_csv(\"Q_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_array = []\n",
    "for i in range(len(y)):\n",
    "    y_array.append(i)\n",
    "y1 = y\n",
    "x1 = y_array\n",
    "plt.plot(x1,y,\"b\") #actual\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y)\n",
    "r_avg = np.empty(N)\n",
    "for t in range(N):\n",
    "    r_avg[t] = np.mean(y[max(0,t-100):(t+1)])\n",
    "plt.plot(r_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range (20):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    print(\"-----------------------\")\n",
    "    #time.sleep(1)\n",
    "    count = 0\n",
    "    state = get_state_as_string(assign_bins(observation,bins))\n",
    "    while not done:\n",
    "        env.render()\n",
    "        act,_ = q_states_dict(table[state])\n",
    "        observation,reward,done,_ = env.step(act)\n",
    "        state = get_state_as_string(assign_bins(observation,bins))\n",
    "        count+=1\n",
    "        if done:\n",
    "            print(\"counter\", count)\n",
    "            break\n",
    "            \n",
    "        state = get_state_as_string(assign_bins(observation,bins))\n",
    "\n",
    "env.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
